{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-15T18:54:21.344026Z",
     "iopub.status.busy": "2025-02-15T18:54:21.343685Z",
     "iopub.status.idle": "2025-02-15T18:54:29.766318Z",
     "shell.execute_reply": "2025-02-15T18:54:29.765215Z",
     "shell.execute_reply.started": "2025-02-15T18:54:21.344000Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "! pip install pandas scikit-learn keybert transformers torch huggingface_hub keyphrase-vectorizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-15T18:54:29.768208Z",
     "iopub.status.busy": "2025-02-15T18:54:29.767890Z",
     "iopub.status.idle": "2025-02-15T18:54:56.607821Z",
     "shell.execute_reply": "2025-02-15T18:54:56.607108Z",
     "shell.execute_reply.started": "2025-02-15T18:54:29.768175Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "import gc\n",
    "import itertools\n",
    "import warnings\n",
    "import configparser\n",
    "\n",
    "# Third-party imports\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "import torch\n",
    "from typing import List, Dict, Tuple, Union, Any\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Hugging Face imports\n",
    "from huggingface_hub import login\n",
    "from transformers import pipeline, AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "# KeyBERT and Sentence Transformers imports\n",
    "from keybert import KeyBERT, KeyLLM\n",
    "from keybert.llm import TextGeneration\n",
    "from keyphrase_vectorizers import KeyphraseCountVectorizer\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set-Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-15T18:54:56.609481Z",
     "iopub.status.busy": "2025-02-15T18:54:56.609167Z",
     "iopub.status.idle": "2025-02-15T18:54:56.737010Z",
     "shell.execute_reply": "2025-02-15T18:54:56.736312Z",
     "shell.execute_reply.started": "2025-02-15T18:54:56.609432Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Load Hugging Face Token\n",
    "config = configparser.ConfigParser()\n",
    "config.read('./config.ini')\n",
    "HF_TOKEN = config['hf_token']['access_token']  # For Hugging Face\n",
    "login(HF_TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-15T18:54:56.738087Z",
     "iopub.status.busy": "2025-02-15T18:54:56.737893Z",
     "iopub.status.idle": "2025-02-15T18:54:56.741518Z",
     "shell.execute_reply": "2025-02-15T18:54:56.740710Z",
     "shell.execute_reply.started": "2025-02-15T18:54:56.738070Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load SemEval data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-15T18:54:56.742394Z",
     "iopub.status.busy": "2025-02-15T18:54:56.742187Z",
     "iopub.status.idle": "2025-02-15T18:54:56.903815Z",
     "shell.execute_reply": "2025-02-15T18:54:56.902961Z",
     "shell.execute_reply.started": "2025-02-15T18:54:56.742352Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!ls data/SemEval2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-15T18:54:56.905201Z",
     "iopub.status.busy": "2025-02-15T18:54:56.904860Z",
     "iopub.status.idle": "2025-02-15T18:54:56.909087Z",
     "shell.execute_reply": "2025-02-15T18:54:56.908193Z",
     "shell.execute_reply.started": "2025-02-15T18:54:56.905168Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "root_doc= 'data/SemEval2017/docsutf8/'\n",
    "root_key= 'data/SemEval2017/keys/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-15T18:54:56.910354Z",
     "iopub.status.busy": "2025-02-15T18:54:56.910027Z",
     "iopub.status.idle": "2025-02-15T18:54:59.688428Z",
     "shell.execute_reply": "2025-02-15T18:54:59.687555Z",
     "shell.execute_reply.started": "2025-02-15T18:54:56.910325Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Creazione di una lista per salvare i dati\n",
    "data = []\n",
    "\n",
    "# Scansione della cartella per leggere i file .txt\n",
    "for filename in os.listdir(root_doc):\n",
    "    if filename.endswith(\".txt\"):  # Controlla che sia un file di testo\n",
    "        file_path = os.path.join(root_doc, filename)\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "            content = file.read()\n",
    "        data.append({\"ID\": re.sub('.txt', '', filename), \"text\": content})\n",
    "\n",
    "# Creazione del DataFrame\n",
    "doc_df = pd.DataFrame(data)\n",
    "doc_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-15T18:54:59.691428Z",
     "iopub.status.busy": "2025-02-15T18:54:59.691200Z",
     "iopub.status.idle": "2025-02-15T18:55:02.298885Z",
     "shell.execute_reply": "2025-02-15T18:55:02.298058Z",
     "shell.execute_reply.started": "2025-02-15T18:54:59.691409Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Creazione di una lista per salvare i dati\n",
    "data = []\n",
    "\n",
    "# Scansione della cartella per leggere i file .txt\n",
    "for filename in os.listdir(root_key):\n",
    "    if filename.endswith(\".key\"):  # Controlla che sia un file di testo\n",
    "        file_path = os.path.join(root_key, filename)\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "            content = file.read() # sep '\\n'\n",
    "        data.append({\"ID\": re.sub('.key', '', filename), \"keys\": content})\n",
    "\n",
    "# Creazione del DataFrame\n",
    "key_df = pd.DataFrame(data)\n",
    "key_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-15T18:55:02.300314Z",
     "iopub.status.busy": "2025-02-15T18:55:02.300063Z",
     "iopub.status.idle": "2025-02-15T18:55:02.323225Z",
     "shell.execute_reply": "2025-02-15T18:55:02.322541Z",
     "shell.execute_reply.started": "2025-02-15T18:55:02.300292Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "sem_eval_df = pd.merge(doc_df, key_df, on=\"ID\")\n",
    "sem_eval_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test different KeyWords approaches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-15T18:55:02.324350Z",
     "iopub.status.busy": "2025-02-15T18:55:02.324046Z",
     "iopub.status.idle": "2025-02-15T18:55:02.337908Z",
     "shell.execute_reply": "2025-02-15T18:55:02.337151Z",
     "shell.execute_reply.started": "2025-02-15T18:55:02.324328Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def compute_metrics(pred_kw, true_kw):\n",
    "    \"\"\"\n",
    "    Computes precision, recall, and F1-score for keyword/keyphrase extraction.\n",
    "\n",
    "    Args:\n",
    "        pred_kw (list of list): Nested lists with predicted keywords/keyphrases.\n",
    "                                Ogni lista interna contiene tuple, dove il primo elemento è la keyword.\n",
    "        true_kw (list of list): Nested lists with true keywords/keyphrases.\n",
    "\n",
    "    Returns:\n",
    "        dict: Dictionary with evaluation metrics (precision, recall, F1-score).\n",
    "    \"\"\"\n",
    "    precision_list, recall_list, f1_list = [], [], []\n",
    "    \n",
    "    for pred, true in zip(pred_kw, true_kw):\n",
    "        pred_keywords = list(dict.fromkeys([p[0] for p in pred])) if pred else []\n",
    "        true_keywords = list(dict.fromkeys(true)) if true else []\n",
    "        \n",
    "        pred_set = set(pred_keywords)\n",
    "        true_set = set(true_keywords)\n",
    "        if pred_set:\n",
    "            precision = len(pred_set & true_set) / len(pred_set)\n",
    "        else:\n",
    "            precision = 0.0\n",
    "        \n",
    "        if true_set:\n",
    "            recall = len(pred_set & true_set) / len(true_set)\n",
    "        else:\n",
    "            recall = 0.0\n",
    "        \n",
    "        if precision + recall == 0:\n",
    "            f1 = 0.0\n",
    "        else:\n",
    "            f1 = 2 * precision * recall / (precision + recall)\n",
    "        \n",
    "        precision_list.append(precision)\n",
    "        recall_list.append(recall)\n",
    "        f1_list.append(f1)\n",
    "    \n",
    "    eval_dict = {\n",
    "        \"precision\": sum(precision_list) / len(precision_list) if precision_list else 0,\n",
    "        \"recall\": sum(recall_list) / len(recall_list) if recall_list else 0,\n",
    "        \"f1_score\": sum(f1_list) / len(f1_list) if f1_list else 0,\n",
    "    }\n",
    "    \n",
    "    return eval_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-15T19:43:17.380526Z",
     "iopub.status.busy": "2025-02-15T19:43:17.380184Z",
     "iopub.status.idle": "2025-02-15T19:43:17.394697Z",
     "shell.execute_reply": "2025-02-15T19:43:17.393582Z",
     "shell.execute_reply.started": "2025-02-15T19:43:17.380498Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "KEY_LLM_PROMPT = \"\"\"\n",
    "<s>[INST] <<SYS>>\n",
    "\n",
    "You are a helpful assistant specialized in extracting comma-separated keywords.\n",
    "You are to the point and only give the answer in isolation without any chat-based fluff.\n",
    "\n",
    "<</SYS>>\n",
    "I have the following document:\n",
    "- The website mentions that it only takes a couple of days to deliver but I still have not received mine.\n",
    "\n",
    "Please give me the keywords that are present in this document and separate them with commas.\n",
    "Make sure you to only return the keywords and say nothing else. For example, don't say:\n",
    "\"Here are the keywords present in the document\"\n",
    "[/INST] meat, beef, eat, eating, emissions, steak, food, health, processed, chicken [INST]\n",
    "\n",
    "I have the following document:\n",
    "- [DOCUMENT]\n",
    "\n",
    "With the following candidate keywords:\n",
    "- [CANDIDATES]\n",
    "\n",
    "Please give me the keywords that are present in this document and separate them with commas.\n",
    "Make sure you to only return the keywords and say nothing else. For example, don't say:\n",
    "\"Here are the keywords present in the document\"\n",
    "[/INST]\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def initialize_models(embedding_model, llm_model, use_keyllm=True):\n",
    "    \"\"\"\n",
    "    Loads and initializes machine learning models for embeddings, keyword extraction, text generation, \n",
    "    question answering, and summarization, using GPU if available.\n",
    "\n",
    "    Args:\n",
    "        embedding_model (str): Model for sentence embeddings. Defaults to 'all-MiniLM-L6-v2'.\n",
    "        llm_model (str): Model for text generation. Defaults to 'gpt-2'.\n",
    "        qa_model (str): Model for question answering. Defaults to 'distilbert-base-cased-distilled-squad'.\n",
    "        sum_model (str): Model for summarization. Defaults to 'facebook/bart-large-cnn'.\n",
    "\n",
    "    Returns:\n",
    "        tuple: Initialized models:\n",
    "            - SentenceTransformer for embeddings.\n",
    "            - KeyBERT for keyword extraction.\n",
    "            - KeyLLM for LLM-based keyword extraction.\n",
    "            - HuggingFace pipelines for question answering and summarization.\n",
    "    \"\"\"\n",
    "    \n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    try:\n",
    "        # Initialize the sentence transformer model\n",
    "        print(\"Loading Sentence Transformer model...\")\n",
    "        model = SentenceTransformer(embedding_model, device=device)\n",
    "        \n",
    "        # Initialize the KeyBERT model\n",
    "        print(\"Loading KeyBERT model...\")\n",
    "        kw_bert_model = KeyBERT(model)\n",
    "        \n",
    "        # Initialize the KeyLLM model\n",
    "        if use_keyllm:\n",
    "            print(\"Loading KeyLLM model...\")\n",
    "            tokenizer = AutoTokenizer.from_pretrained(llm_model)\n",
    "            llm_model = AutoModelForCausalLM.from_pretrained(\n",
    "                llm_model,\n",
    "                trust_remote_code=True,\n",
    "                device_map='auto'\n",
    "            )\n",
    "            generator = pipeline(\n",
    "                model=llm_model, tokenizer=tokenizer,\n",
    "                task='text-generation',\n",
    "                max_new_tokens=50,\n",
    "                repetition_penalty=1.1,\n",
    "                model_kwargs={\"load_in_4bit\": True}\n",
    "            )\n",
    "            llm = TextGeneration(generator, prompt=KEY_LLM_PROMPT)\n",
    "            kw_llm_model = KeyLLM(llm)\n",
    "        else:\n",
    "            kw_llm_model = None\n",
    "        \n",
    "        print(\"Models loaded successfully!\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while loading the models: {e}\")\n",
    "    \n",
    "    return model, kw_bert_model, kw_llm_model\n",
    "\n",
    "def get_top_kw (doc, candidates, model, top_n):\n",
    "    \"\"\"\n",
    "    Get top keywords based on similarity to the document.\n",
    "    \n",
    "    Args:\n",
    "        doc: Input document text\n",
    "        candidates: List of candidate keywords\n",
    "        model: SentenceTransformer model for encoding\n",
    "        top_n: Number of top keywords to return\n",
    "    \n",
    "    Returns:\n",
    "        List of tuples containing (keyword, similarity_score)\n",
    "    \"\"\"\n",
    "    # Encode document and candidates\n",
    "    doc_embedding = model.encode(doc).reshape(1, -1)  # Reshape for sklearn\n",
    "    candidate_embeddings = model.encode(candidates)\n",
    "    \n",
    "    # Calculate cosine similarities using sklearn\n",
    "    similarities = cosine_similarity(candidate_embeddings, doc_embedding).flatten()\n",
    "    \n",
    "    # Get top keywords with their scores\n",
    "    top_indices = similarities.argsort()[-top_n:][::-1]\n",
    "    return [(candidates[idx], float(similarities[idx])) for idx in top_indices]\n",
    "    \n",
    "def extract_keywords_from_text(doc, kw_bert_model, kw_llm_model, model, use_keyllm, diversity, top_n):\n",
    "    \"\"\"\n",
    "    Extract keywords from text using KeyBERT and optionally KeyLLM.\n",
    "    \n",
    "    Args:\n",
    "        doc: Input text\n",
    "        kw_bert_model: KeyBERT model instance\n",
    "        kw_llm_model: KeyLLM model instance (optional)\n",
    "        model: SentenceTransformer model for encoding\n",
    "        use_keyllm: Whether to use KeyLLM for refinement\n",
    "        diversity: Diversity parameter for MMR\n",
    "        top_n: Number of keywords to extract\n",
    "    \n",
    "    Returns:\n",
    "        List of tuples containing (keyword, score)\n",
    "    \"\"\"\n",
    "    def extract_with_keybert(n: int) -> List[Tuple[str, float]]:\n",
    "        \"\"\"Helper function for KeyBERT extraction with error handling\"\"\"\n",
    "        try:\n",
    "            return kw_bert_model.extract_keywords(\n",
    "                docs=doc,\n",
    "                vectorizer=KeyphraseCountVectorizer(),\n",
    "                use_mmr=True,\n",
    "                diversity=diversity,\n",
    "                top_n=n\n",
    "            )\n",
    "        except ValueError as e:\n",
    "            print(f\"KeyphraseCountVectorizer failed, falling back to default: {e}\")\n",
    "            return kw_bert_model.extract_keywords(\n",
    "                docs=doc,\n",
    "                use_mmr=True,\n",
    "                diversity=diversity,\n",
    "                top_n=n\n",
    "            )\n",
    "\n",
    "    if use_keyllm:\n",
    "        # Get initial keywords from KeyBERT (limited to 20 for LLM processing)\n",
    "        initial_keywords = extract_with_keybert(20)\n",
    "        initial_keyword_texts = [kw[0] for kw in initial_keywords]\n",
    "        # Refine using KeyLLM\n",
    "        refined_keywords = kw_llm_model.extract_keywords(\n",
    "            docs=doc,\n",
    "            candidate_keywords=initial_keywords\n",
    "        )[0]\n",
    "        # Combine and deduplicate candidates\n",
    "        all_candidates = list(set(initial_keyword_texts) | set(refined_keywords))\n",
    "        all_candidates = [c for c in all_candidates if c]  # Remove empty strings\n",
    "        # Get final keywords based on similarity\n",
    "        print(initial_keywords)\n",
    "        print(refined_keywords)\n",
    "        return get_top_kw(doc, all_candidates, model, top_n)\n",
    "    \n",
    "    # Use KeyBERT only\n",
    "    return extract_with_keybert(top_n)\n",
    "\n",
    "\n",
    "def test_keywords_extraction(kw_bert_model, kw_llm_model, model, texts, true_kw, use_keyllm, diversity, top_n):\n",
    "    \"\"\"\n",
    "    Tests keyword extraction with KeyBERT or KeyBERT + LLM, calculating execution time and metrics.\n",
    "\n",
    "    Args:\n",
    "        kw_bert_model: KeyBERT model for keyword extraction.\n",
    "        kw_llm_model: LLM model for refining keywords (used only if use_keyllm=True).\n",
    "        texts (list of str): List of texts to process.\n",
    "        true_kw (list of list): List of reference keywords.\n",
    "        use_keyllm (bool): If True, use KeyBERT + LLM. If False, use only KeyBERT.\n",
    "        diversity (float): Diversity parameter for MMR.\n",
    "        top_n (int): Maximum number of keywords to extract per text.\n",
    "\n",
    "    Returns:\n",
    "        dict: Dictionary with execution time and precision, recall, and F1-score metrics.\n",
    "    \"\"\"\n",
    "    pred_kw = []\n",
    "    start_time = time.time()  # Start time measurement\n",
    "\n",
    "    # Generate keywords for each text\n",
    "    for text in tqdm(texts, desc=\"Processing texts\"):\n",
    "        print(text)\n",
    "        keywords_list = extract_keywords_from_text(text, kw_bert_model, kw_llm_model, model, use_keyllm, diversity, top_n)\n",
    "        pred_kw.append(keywords_list)\n",
    "\n",
    "    end_time = time.time()  # End time measurement\n",
    "\n",
    "    # Calculate performance metrics\n",
    "    eval_metrics = compute_metrics(pred_kw, true_kw)\n",
    "    eval_metrics[\"execution_time\"] = end_time - start_time\n",
    "\n",
    "    return eval_metrics\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-15T19:43:17.655098Z",
     "iopub.status.busy": "2025-02-15T19:43:17.654870Z",
     "iopub.status.idle": "2025-02-15T19:43:17.794319Z",
     "shell.execute_reply": "2025-02-15T19:43:17.793534Z",
     "shell.execute_reply.started": "2025-02-15T19:43:17.655078Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def grid_search_extraction(param_combinations, texts, true_kw):\n",
    "    \"\"\"\n",
    "    Performs a Grid Search to test different parameter combinations\n",
    "    in the test_extraction function, freeing GPU memory between iterations.\n",
    "\n",
    "    Args:\n",
    "        param_combinations (list of tuples): List with all parameter combinations.\n",
    "        texts (list of str): List of texts to process.\n",
    "        true_kw (list of list): List of reference keywords.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with metric results for each combination.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "\n",
    "    # Test each parameter combination\n",
    "    for embedding_model, llm_model, use_keyllm, diversity, top_n in tqdm(param_combinations, desc=\"Processing parameter combinations\"):\n",
    "\n",
    "        print(f\"Testing: emb_model={embedding_model}, llm_model={llm_model}, use_keyllm={use_keyllm}, diversity={diversity}, top_n={top_n}\")\n",
    "\n",
    "        # Initialize the KeyBERT model with the specified embedding model\n",
    "        embedding_model, kw_bert_model, kw_llm_model = initialize_models(embedding_model, llm_model, use_keyllm)\n",
    "\n",
    "        # Start the test with the current parameters\n",
    "        metrics = test_keywords_extraction(\n",
    "            kw_bert_model, kw_llm_model, embedding_model, texts, true_kw,\n",
    "            use_keyllm=use_keyllm, diversity=diversity, top_n=top_n\n",
    "        )\n",
    "\n",
    "        # Save the results in a list\n",
    "        results.append({\n",
    "            \"embedding_model\": embedding_model,\n",
    "            \"llm_model\": llm_model,\n",
    "            \"use_keyllm\": use_keyllm,\n",
    "            \"diversity\": diversity,\n",
    "            \"top_n\": top_n,\n",
    "            \"precision\": metrics[\"precision\"],\n",
    "            \"recall\": metrics[\"recall\"],\n",
    "            \"f1_score\": metrics[\"f1_score\"],\n",
    "            \"execution_time\": metrics[\"execution_time\"]\n",
    "        })\n",
    "\n",
    "        del kw_bert_model\n",
    "        del kw_llm_model\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    # Convert the results to a DataFrame for easier analysis\n",
    "    results_df = pd.DataFrame(results)\n",
    "    \n",
    "    return results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-15T19:43:17.803225Z",
     "iopub.status.busy": "2025-02-15T19:43:17.803008Z",
     "iopub.status.idle": "2025-02-15T19:43:17.810235Z",
     "shell.execute_reply": "2025-02-15T19:43:17.809549Z",
     "shell.execute_reply.started": "2025-02-15T19:43:17.803205Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Define parameters for Grid Search\n",
    "param_grid = {\n",
    "    \"embedding_model\": [\"all-MiniLM-L6-v2\", \"paraphrase-MiniLM-L12-v2\"],  # KeyBERT embedding models\n",
    "    \"llm_model\": [\"meta-llama/Llama-3.2-3B\", \"Qwen/Qwen2.5-3B\"],  # LLM models for KeyLLM\n",
    "    \"use_keyllm\": [True, False],  # Test both KeyBERT and KeyBERT + LLM\n",
    "    \"diversity\": [0.3, 0.5, 0.7],  # Variation of the MMR parameter\n",
    "    \"top_n\": [3, 5, 10]  # Maximum number of extracted keywords\n",
    "}\n",
    "\n",
    "# Generate all possible parameter combinations\n",
    "param_combinations = list(itertools.product(\n",
    "    param_grid[\"embedding_model\"],\n",
    "    param_grid[\"llm_model\"],\n",
    "    param_grid[\"use_keyllm\"],\n",
    "    param_grid[\"diversity\"],\n",
    "    param_grid[\"top_n\"]\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-15T19:43:17.938107Z",
     "iopub.status.busy": "2025-02-15T19:43:17.937912Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "texts = sem_eval_df[\"text\"].tolist()\n",
    "true_kw = sem_eval_df[\"keys\"].str.split(\"\\n\").tolist()\n",
    "\n",
    "# Test della funzione grid_search_extraction\n",
    "results_df = grid_search_extraction(param_combinations, texts, true_kw)\n",
    "print(\"Grid Search Results:\")\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# pick the best model\n",
    "best_f1_params = results_df.iloc[results_df[\"f1_score\"].idxmax()]\n",
    "best_precision_params = results_df.iloc[results_df[\"precision\"].idxmax()]\n",
    "best_recall_params = results_df.iloc[results_df[\"recall\"].idxmax()]\n",
    "\n",
    "# print the best model parameters\n",
    "print(\"Best F1 Score Parameters:\")\n",
    "print(best_f1_params)\n",
    "print(\"\\nBest Precision Parameters:\")\n",
    "print(best_precision_params)\n",
    "print(\"\\nBest Recall Parameters:\")\n",
    "print(best_recall_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 6663395,
     "sourceId": 10744752,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30886,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
